{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "master=glob.glob(\"Data/*.htm\") #To read all the files in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/Page 2 of 50 for Health Insurance Reviews by Ratings & City.htm',\n",
       " 'Data/Page 9 of 50 for Health Insurance Reviews by Ratings & City.htm',\n",
       " 'Data/Page 5 of 50 for Health Insurance Reviews by Ratings & City.htm',\n",
       " 'Data/Page 16 of 50 for Health Insurance Reviews by Ratings & City.htm']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We extract the contents of the files into one single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "S=\" \"\n",
    "html_array=[]\n",
    "for file in master:\n",
    "    f=codecs.open(file, 'r')\n",
    "    html_array.append(f.read()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = S.join(html_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html.count(\"text_here review-desc-more\") # A test  to check extraction, marker mentioned later.\n",
    "#Avoid opening the full file, too big and useless. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to parse the file to extract the exact reviews from the respective files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_html=BeautifulSoup(html,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=parsed_html.find_all('div',attrs={'class':\"text_here review-desc-more\",'itemprop':\"description\"})\n",
    "\n",
    "### Refer to the readme to discuss the tags and markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"text_here review-desc-more\" itemprop=\"description\">\n",
       "                                 The services are good from Apollo Munich and this is the reason for taking a health policy. Its been 4 years and need to renew the policy yearly once. The premium is around 6K through cheque. I do have claim experience. The policy coverage is 5L.</div>,\n",
       " <div class=\"text_here review-desc-more\" itemprop=\"description\">\n",
       "                                 I BOUGHT FOR MY PARENTS AND POLICY NUMBER IS 13110445 WHEN I PURCHASED RELIGARE CARE PLAN LAST YEAR WITH PREMIUM 25282 BUT NOW MY PREMIUM PLUNGE LIKE HORSE BY 9570 Rs AND NOW IT IS 34852 .\n",
       " I HAVE MAILED MANY TIMES BUT THEY ALSO DONT KNOW HOW COMPANY DOES WORK... CUSTOMER SERVICE ALSO NOT GOOD THEY ALSO DONT KNOW HOW TO SPEAK WITH EXISTING CUSTOMER. </div>,\n",
       " <div class=\"text_here review-desc-more\" itemprop=\"description\">\n",
       "                                 Last 2 years, i have been renewing the health insurance policy from ICICI Lombard. I was a medial representative of ICICI Lombard with a corporate hospitals and they have given me a good coverage value as well. This policy covered with Health insurance and accidental benefits. They gave me a huge coverage value of Rs. 20 lakhs.</div>,\n",
       " <div class=\"text_here review-desc-more\" itemprop=\"description\">\n",
       "                                 I have taken a health insurance in IFFCO TOKIO GENERAL INSURANCE on 3 years before. I am paying premium in the yearly package. It covers my whole family for this insurance. They have tied up with many hospitals and cashless treatment also applicable. </div>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=parsed_html.find_all('div',attrs={'class':'rating-section review-user-score',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"rating-section review-user-score\">\n",
       " <div class=\"medium-rating rating review-score-container\" id=\"review.reviewRating.customer.1\" title=\"Great!\">\n",
       " <span class=\"star-rating star-rating-4-0\"></span>\n",
       " <input name=\"review.reviewRating.customer.1\" type=\"hidden\" value=\"4.0\"/>\n",
       " </div> <span> <span class=\"dontshow\">0.5</span>\n",
       " <span>4.0</span>/<span>5</span></span> \"Great!\"\n",
       "                             </div>,\n",
       " <div class=\"rating-section review-user-score\">\n",
       " <div class=\"medium-rating rating review-score-container\" id=\"review.reviewRating.customer.2\" title=\"Unacceptable\">\n",
       " <span class=\"star-rating star-rating-0-5\"></span>\n",
       " <input name=\"review.reviewRating.customer.2\" type=\"hidden\" value=\"0.5\"/>\n",
       " </div> <span> <span class=\"dontshow\">0.5</span>\n",
       " <span>0.5</span>/<span>5</span></span> \"Unacceptable\"\n",
       "                             </div>,\n",
       " <div class=\"rating-section review-user-score\">\n",
       " <div class=\"medium-rating rating review-score-container\" id=\"review.reviewRating.customer.3\" title=\"Blown away!\">\n",
       " <span class=\"star-rating star-rating-5-0\"></span>\n",
       " <input name=\"review.reviewRating.customer.3\" type=\"hidden\" value=\"5.0\"/>\n",
       " </div> <span> <span class=\"dontshow\">0.5</span>\n",
       " <span>5.0</span>/<span>5</span></span> \"Blown Away!\"\n",
       "                             </div>,\n",
       " <div class=\"rating-section review-user-score\">\n",
       " <div class=\"medium-rating rating review-score-container\" id=\"review.reviewRating.customer.4\" title=\"Satisfactory\">\n",
       " <span class=\"star-rating star-rating-3-0\"></span>\n",
       " <input name=\"review.reviewRating.customer.4\" type=\"hidden\" value=\"3.0\"/>\n",
       " </div> <span> <span class=\"dontshow\">0.5</span>\n",
       " <span>3.0</span>/<span>5</span></span> \"Satisfactory\"\n",
       "                             </div>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[1:5]\n",
    "#Accepted this for the lack of a cleaner direct tag. Will take care of it during cleaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=str(ratings[0])\n",
    "float(l[(l.find('value=')+7):(l.find('value=')+10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(y):\n",
    "    clean=re.compile('<.*?>')\n",
    "    cleantext=re.sub(clean,'',y)\n",
    "    return (cleantext.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rews=[]\n",
    "for i in range(0,len(reviews)):\n",
    "    rews.append(cleanhtml(reviews[i].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The services are good from Apollo Munich and this is the reason for taking a health policy. Its been 4 years and need to renew the policy yearly once. The premium is around 6K through cheque. I do have claim experience. The policy coverage is 5L.',\n",
       " 'I BOUGHT FOR MY PARENTS AND POLICY NUMBER IS 13110445 WHEN I PURCHASED RELIGARE CARE PLAN LAST YEAR WITH PREMIUM 25282 BUT NOW MY PREMIUM PLUNGE LIKE HORSE BY 9570 Rs AND NOW IT IS 34852 .\\nI HAVE MAILED MANY TIMES BUT THEY ALSO DONT KNOW HOW COMPANY DOES WORK... CUSTOMER SERVICE ALSO NOT GOOD THEY ALSO DONT KNOW HOW TO SPEAK WITH EXISTING CUSTOMER.',\n",
       " 'Last 2 years, i have been renewing the health insurance policy from ICICI Lombard. I was a medial representative of ICICI Lombard with a corporate hospitals and they have given me a good coverage value as well. This policy covered with Health insurance and accidental benefits. They gave me a huge coverage value of Rs. 20 lakhs.',\n",
       " 'I have taken a health insurance in IFFCO TOKIO GENERAL INSURANCE on 3 years before. I am paying premium in the yearly package. It covers my whole family for this insurance. They have tied up with many hospitals and cashless treatment also applicable.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rews[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanrats(y):\n",
    "    return(float(y[(y.find('value=')+7):(y.find('value=')+10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rats=[]\n",
    "for i in range(0,len(ratings)):\n",
    "    rats.append(cleanrats(str(ratings[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.0, 0.5, 5.0, 3.0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rats[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Reviews': rews, 'Ratings': rats})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Reviews']=df['Reviews'].replace(r'\\n',' ',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Reviews'].apply(lambda x:x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reviews     object\n",
       "Ratings    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_calculation(y):\n",
    "    if y['Ratings']<4.0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# we can play with the sentiment paramenter, or even non-binary sentiments according to our requirement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment']=df.apply(sentiment_calculation,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have taken a health insurance with ICICI LOM...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The services are good from Apollo Munich and t...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I BOUGHT FOR MY PARENTS AND POLICY NUMBER IS 1...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Last 2 years, i have been renewing the health ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have taken a health insurance in IFFCO TOKIO...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Currently my health policy is in Star Health b...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews  Ratings  Sentiment\n",
       "0  I have taken a health insurance with ICICI LOM...      3.0          0\n",
       "1  The services are good from Apollo Munich and t...      4.0          1\n",
       "2  I BOUGHT FOR MY PARENTS AND POLICY NUMBER IS 1...      0.5          0\n",
       "3  Last 2 years, i have been renewing the health ...      5.0          1\n",
       "4  I have taken a health insurance in IFFCO TOKIO...      3.0          0\n",
       "5  Currently my health policy is in Star Health b...      4.0          1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Health insurance reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=df.Reviews, df.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating feature vectors and the sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function to conevert both the train data and the test data into feature vectors.\n",
    "def tfidf_extractor(corpus, ngram_range=(1,1)):\n",
    "    vectorizer=TfidfVectorizer(min_df=1,\n",
    "                              norm='l2',\n",
    "                              smooth_idf=True,\n",
    "                              use_idf=True,\n",
    "                              ngram_range=ngram_range)\n",
    "    features=vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer, tfidf_train_features=tfidf_extractor(x_train)\n",
    "tfidf_test_features=tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<132x1074 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5400 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tfidf_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11639807, 0.07429508, 0.10762987, ..., 0.1188461 , 0.05510784,\n",
       "       0.06465765])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train_features.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28936975, 0.71068585, 0.16115809, ..., 0.23685743, 0.30198511,\n",
       "       0.1454835 ])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_test_features.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(true_labels, predicted_labels):\n",
    "    print(\"Accuracy:\",np.round(metrics.accuracy_score(true_labels, predicted_labels),2))\n",
    "    print(\"Precision:\",np.round(metrics.precision_score(true_labels, predicted_labels,average='weighted'),2))\n",
    "    print(\"Recall:\",np.round(metrics.recall_score(true_labels, predicted_labels,average='weighted'),2))\n",
    "    print(\"f1:\",np.round(metrics.f1_score(true_labels, predicted_labels,average='weighted'),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_eval_model(classifier, train_features, train_labels, test_features, test_labels):\n",
    "    classifier.fit(train_features,train_labels)\n",
    "    predictions=classifier.predict(test_features)\n",
    "    print(type(predictions))\n",
    "    get_metrics(true_labels=test_labels, predicted_labels=predictions)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test and Evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_best=MultinomialNB(alpha=0.001, fit_prior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Accuracy: 0.8\n",
      "Precision: 0.74\n",
      "Recall: 0.8\n",
      "f1: 0.73\n"
     ]
    }
   ],
   "source": [
    "mnb_tfidf_predictions= train_test_eval_model(classifier=mnb_best,\n",
    "                                            train_features=tfidf_train_features,\n",
    "                                            train_labels=y_train,\n",
    "                                            test_features=tfidf_test_features,\n",
    "                                            test_labels=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(mnb_tfidf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(mnb_tfidf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.07      0.13        27\n",
      "           1       0.80      0.98      0.88       105\n",
      "\n",
      "    accuracy                           0.80       132\n",
      "   macro avg       0.65      0.53      0.51       132\n",
      "weighted avg       0.74      0.80      0.73       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,mnb_tfidf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2  25]\n",
      " [  2 103]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,mnb_tfidf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
